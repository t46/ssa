### **WVS Wave 7（2017-2022）米国データを利用したパイプライン案**

**ステップ 0\. 前提：必要ファイルをまとめて取得**

https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp から下記データを取得

| 分類                   | ファイル名（v6.0.0 例）                                 | 目的                                 |
| :--------------------- | :------------------------------------------------------ | :----------------------------------- |
| **個票データ**         | `WVS_Cross-National_Wave_7_csv_v6_0.csv`  | 回答者レコード（66 国分一括）        |
| **英語マスター質問票** | `F00010738-WVS-7_Master_Questionnaire_2017-2020_English.pdf`    | 全質問文・選択肢・スキップパターン   |
| **データコードブック** | `F00011055-WVS7_Codebook_Variables_report_V6.0.pdf`                                   | 変数ラベル・欠測コード・ウェイト説明 |

**ステップ 1｜データ取り込み&前処理**

1. 上記ファイルを `data/raw/` に自動ダウンロード。   
2. `WVS_Cross-National_Wave_7_csv_v6_0.csv` から `B_COUNTRY == 840（USA）`のレコードのみを抽出し `data/processed/usa_w7.csv` として保存。
3. 質問票 (`F00010738-WVS-7_Master_Questionnaire_2017-2020_English.pdf`) から質問を key とする JSON ファイルを生成し、`code-maps/questionnaire_map.json` として保存
4. コードブック (`F00011055-WVS7_Codebook_Variables_report_V6.0.pdf`) から変数を key とする JSON ファイルを生成し、`code-maps/codebook_map.json` として保存（全ての変数名は `meta-data/all_variable_names` に保存）

**ステップ 3｜LLM による研究アイデア創出**

1. **プロンプト**：

「米国の人々の価値観に関して社会科学者が関心を持ちそうな研究テーマを3案提案してください。目的／理論背景／検証仮説を含めてください」

2. *目的→背景→仮説→分析指標* を YAML（一例） として spec/research.yaml に出力。

**ステップ 4｜変数マッピング自動化**

1. YAML 内キーワードをベクトル DB に照会し候補変数を取得。  
2. 候補の尺度・選択肢が米国版質問票と整合するかをルールベースで検証。  
3. 最終マッピングを spec/variables.yaml に保存（例：幸福感＝Q49, 政府信頼＝Q57）。

**ステップ 5｜先行研究探索 & 意義要約**

1. Semantic Scholar / CrossRef API でマッピング変数に関連する近年（2015-2025）の査読論文を自動検索。  
2. LLM が各論文の研究目的・方法・結果を要約し、提案仮説とのギャップを抽出。  
3. Markdown レポート literature\_review.md を生成（意義・空白領域を箇条書き）。

**ステップ 6｜分析コード生成と実行**

1. LangChain の code-writer エージェントが analysis/auto\_usa\_w7.ipynb を生成：  
   * S017 ウェイト適用  
   * 欠測処理とカテゴリ再符号化  
   * ロジスティック／OLS／重回帰など仮説別モデル  
2. nbclient でノートブックをバッチ実行し、結果（係数表・図表）を outputs/ に保存。

**ステップ 7｜自動 QC ループ（ここまで設計しなくてもいいかもしれない）**

1. 効果量・95 % CI・仮説方向性を自動判定。  
2. 基準未達なら**モデルの頑健化**（変数変換・サブサンプル・ロバスト標準誤）を再試行。  
3. MLflow で各試行ログを記録し最良モデルをタグ付け。

**ステップ 8｜ドラフト論文生成**

1. LLM が構造化テンプレート（IMRaD）に従い Markdown でドラフト作成。  
2. critic-LLM が数値の引用ミスや論理飛躍を指摘し自動修正。  
3. Pandoc フィルターで LaTeX へ変換し、図 (\\includegraphics{fig1.svg})・表 (\\input{table1.tex}) を自動挿入。

**ステップ 9｜引用・公開・投稿準備**

1. CrossRef API で DOI を取得し references.bib に BibTeX 自動生成。  
2. WVS データ引用を脚注挿入（例：*Haerpfer et al., 2024\. World Values Survey: Wave 7 Data File v6.0.*）。  
3. GitHub push → Zenodo DOI 付与で再現リポジトリを公開し、目標ジャーナルのクラスファイルに合わせて PDF をビルド。

---

6/25更新

**World Value Surveyとは？**

* 1981年から7波にわたり100か国以上を対象とした大規模国際比較調査であり、政治・宗教・経済・幸福感など多岐にわたる価値観データを時系列で追跡できます。  
* 各国約1,000～1,500人の確率標本を用い、人口規模調整ウェイト（S017）と標準化ウェイト（S018／S019）が提供されるため、国内分析にも国際比較にも対応しやすい設計です。  
* 質問票は英語版マスター＋国別翻訳版が整備され、同じ概念を測る質問が波ごとに再コーディングされているため、LLMなどで自然言語⇔変数マッピングを自動化しやすい構造です。  
* 個票データ（Wave別）と統合タイムシリーズファイルが無償公開され、Stata・SPSS・R・CSV 形式でダウンロード可能。オンライン集計ツールも備わっており、初期探索から本格分析までワンストップで行えます。  
* データとドキュメントはCC BY 4.0相当で再配布禁止・引用必須。

**データ（Wave7）： [https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp](https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp)**

**データファイル／ドキュメント構成**

| 種別                            | 代表ファイル名（例）                                        | 主な内容                                                    | 典型的な利用場面                     |
| :------------------------------ | :---------------------------------------------------------- | :---------------------------------------------------------- | :----------------------------------- |
| **個票データ（Wave 別）**       | WV7\_Dataset\_v6\_0\_0.dta など                             | 1行＝回答者、1列＝変数。原則その波のみの変数名（Q～／V～） | 単一波分析、国×年固定効果モデル      |
| **縦断ファイル（Time-Series）** | WVSTimeseries\_1981\_2022\_v5\_0.dta                        | 7波すべてを統合。変数を A001, B002… に再命名し欠測を最小化  | 長期トレンド、世代比較               |
| **変数一覧・クロスウォーク**    | WVS TimeSeries 1981 2022 Variables Report v5.0.pdf          | 各波→統合ファイルへの対応表、欠測率、ラベル                 | 事前の変数選定・一致確認             |
| **マスター質問票（英語）**      | WVS-7 Master Questionnaire 2017-2021 English.pdf            | 質問文・選択肢・スキップロジック・欠測コード                | LLM に質問文を渡すプロンプト生成     |
| **コードブック／技術報告**      | WV7\_Codebook\_v6.pdf, Technical\_Sampling\_Report\_xxx.pdf | 変数ラベル、値ラベル、サンプリング設計、ウェイト説明        | 変数辞書としてパイプラインに組み込む |
| **国別質問票（翻訳版）**        | Questionnaire\_JPN.pdf など                                 | ローカル言語訳と固有調整項目                                | 多言語 LLM 利用や翻訳検証            |
| **バージョン履歴**              | Versions\_history\_6.0.2.pdf                                | 修正ログ（変数追加・誤値訂正）                              | 再現性確保／アップデート監視         |

 

**パイプラインのイメージ**  
（まずは米国の最新データだけでやる）

* LLMに関係する質問票を読ませて、既存の特定の分野の先行研究を踏まえた上で分析の案を考えさせる  
* 分析するためのPythonコードを書いてもらい、実行してもらう  
* 分析結果をまとめてもらい、インプリケーションを出してもらう。  
* 論文執筆  
  *  先行研究をまとめてきちんと文献情報として最後につける必要性  
  * 図表も入れる

（ちなみに現時点でもmanusに入れるだけである程度それっぽいものはできる）

**Agenda**

* こういう時ってベンチマークはどうするの？  
  * レビューの結果が人間と一緒かどうか（評価としては弱い）  
  * 面白いかどうかを評価させる？  
* それともどこにhumanが入るべきか主張する論文にする？（計算資源の使用量などの結果を踏まえて）  
* それかバイアスについての論文にする？（例えば人間が作った論文に比べてどれだけ内容が偏るのかとか）  
*  CSでarXivに投稿するならあんまり考えなくていい？

→とりあえずコンセプト示せればOK

---

社会科学における研究の自動化をステップごとに考えると

* 理論や先行研究からの仮説の設定  
  * この部分だけは既存のLLMで十分できそう  
  * 例：Automated Social Science: Language Models as Scientist and Subjects  
    * [https://www.nber.org/papers/w32381](https://www.nber.org/papers/w32381)  
    * 社会科学上の仮説を自動で生成し、インシリコ（コンピュータ上の仮想環境）で検証する手法を提示した論文  
  * 知り合いの経済学者が今使えるLLMのモデルは理論的視座が甘いみたいなことを言っていたが、それはトークン長の問題な気がする

* データの収集  
  * インタビュー  
    * AIでインタビューする研究は少しずつではじめている。  
    * ただしインタビューした内容をLLMに学習させるレベルのものはまだ珍しい。「Generative Agent Simulations of 1,000 People」は結構話題になった印象。  
      * [https://hai.stanford.edu/news/ai-agents-simulate-1052-individuals-personalities-with-impressive-accuracy](https://hai.stanford.edu/news/ai-agents-simulate-1052-individuals-personalities-with-impressive-accuracy)  
  * サーベイ実験・調査  
    * 設問作りは簡単そうだし上の仮説生成論文とやることはほぼ変わらない  
    * サーベイ配信まで自動化でやるという論文・サービスは今のところ見たことがない（インタビューの深掘り質問を自動でやるサービスなら結構ある）  
      * おそらく技術的な問題ではなくサーベイ企業側の問題な気はする。QualtricsにAPIはあるけど配信の部分はQualtricsだけじゃできないし...  
  * 既存のデータセットを利用するなら収集されているのでこの点の自動化を考える必要はない  
  * LLMにサーベイ・インタビューに答えさせるものもあるが社会学・心理学界隈の人でそういうことに関心を持っている人でも正直現実との差異がまだまだ大きすぎると思っていてまともに使おうとは思わないのでは。

* データの分析  
  * 質的データ：  
    * 質的データの自動コーディングについての論文はすでにある  
    * NVivoやATLAS.tiといった主要な質的分析ツールは、テキストの自動分類（Auto Code）や感情分析、トピック抽出などの機能を備えており、膨大なテキストデータのパターン検出を高速化しているらしい  
    * AcademiaOS  
      * [https://arxiv.org/html/2403.08844v1](https://arxiv.org/html/2403.08844v1)  
      * 大規模言語モデルを用いてインタビューデータ等のコーディングからテーマ抽出、理論化までを一貫して支援するシステムのプロトタイプらしい  
  * 量的データ：  
    * やることは実質AutoMLと一緒？？予測をしないだけ  
    * モデルの構造や仮定は研究者が事前に設定する必要があり、自動化ツールが扱えるのは[「あらかじめ与えられたモデルに基づいて新たな知見を推論する段階」に主に限定される](https://pmc.ncbi.nlm.nih.gov/articles/PMC11804648)...というのが今までのAIだった気がするが、ManusのようなAGI的なものに投げたらそこは超えられそう  
    * 探索的に回帰分析や因果推論を実行しそれをLLMによってひたすら解釈すれば人間にはできないほど多様な分析ができるはず（計算資源かなり使いそうだけど）  
    * 従来型の理論に基づくモデルよりもデータ駆動で発見されたモデルの方が人間の学習行動をうまく説明できるという話をしている論文がどこかにあったはず

* 示唆出し  
  * LLMでも簡単にできるのはかなり想像しやすいのであんまり重要ではなさそう

* （番外編）LLMのモデル作り  
  * サーベイの個票やインタビューの回答をLLMに追加学習させたらどうなるのか→社会のクローンができたら（バイアスが全く補正できていない）LLMに対して質問をするよりいいものができそう

                 
＜まとめ＞

* 部分ごとに試してみた論文はあるが、データの種類を問わず社会科学の論文を「全部AIで書いてみました論文」は今のところなさそう（というか全部AIで書きました論文はごく一部の分野でしかまだないのでは？）  
* サービス化を考えるのであれば、以下のような方向がありそう  
  * 企業が自社で持っているデータを全自動で探索してレポート化できるようにする  
  * AIがユーザー・自社社員・エキスパートにインタビュー・サーベイ調査して自動でまとめる  
    * さらに進んだバージョンとして大量の質的インタビューデータをLLMに学習させて社会のクローンを作るというアプローチもあり得る（石井はこれを一番やりたい）

　ちなみに上のようなテーマだと石井がNEDOの開拓でもらっているお金を使えます  
